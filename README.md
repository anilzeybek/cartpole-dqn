Solving LunarLander-v2 environment from gym with dqn, double dqn, dueling network architectures, prioritized experience replay with proportional prioritization and REINFORCE algorithms.

Note that PER algorithm works slower than others because of not using some advanced data structures to decrease complexity.

Dependencies:
- Gym
- PyTorch
- Numpy

Papers for some of these algorithms:
- DQN: https://www.nature.com/articles/nature14236
- DDQN: https://arxiv.org/abs/1509.06461
- Dueling DQN: https://arxiv.org/abs/1511.06581
- PER: https://arxiv.org/abs/1511.05952

